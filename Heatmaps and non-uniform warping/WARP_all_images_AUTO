import os, json, cv2
import numpy as np
import pandas as pd
import torch
import torch.nn.functional as F

from tqdm import tqdm
from patch_classifier_utils import initialize_model
from DeformationUtils import extract_patches, warped_imgs

# Use a non-interactive backend for saving figures
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt


# =========================
#        CONFIG
# =========================
device       = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model_name   = "resnet"
num_classes  = 2
batch_size   = 64
patch_size   = 224
stride       = 32

# SWEEP VALUES
fwhm_values  = [15.0, 20.0, 25.0, 30.0]
scale_values = [10.0, 15.0, 20.0, 25.0]

# PATHS
weights_dict = "/home/AD/ses235/Documents/My_Project/VinDr_Mamo/saved_models/20percentcutoff.s10.pth"
bbox_csv     = "/home/AD/ses235/physionet.org/files/vindr-mammo/1.0.0/resized_images_manifestold.csv"
norm_json    = "/home/AD/ses235/Documents/My_Project/VinDr_Mamo/saved_models/train_norm.json"


# =========================
#   OUTPUT FOLDER HELPERS
# =========================
def _fmt_simple(v: float) -> str:
    """Format 3.0 -> '3', 3.50 -> '3.5', 3.25 -> '3.25' (no trailing zeros)."""
    s = f"{v}"
    if "." in s:
        s = s.rstrip("0").rstrip(".")
    return s

_base_root = "/home/AD/ses235/physionet.org/files/vindr-mammo/1.0.0/warped_datasets"


# =========================
#    NORMALIZATION
# =========================
fallback_mean, fallback_std = 0.3385, 0.3344
if os.path.exists(norm_json):
    with open(norm_json, "r") as f:
        _s = json.load(f)
    mean_pixel = float(_s.get("mean", fallback_mean))
    std_pixel  = float(_s.get("std",  fallback_std))
else:
    mean_pixel, std_pixel = fallback_mean, fallback_std
print(f"[INFO] mean/std used -> {mean_pixel:.6f} / {std_pixel:.6f}")


# =========================
#     MODEL: LOAD WEIGHTS
# =========================
model = initialize_model(model_name, num_classes=num_classes, use_pretrained=False).to(device)
ckpt = torch.load(weights_dict, map_location="cpu")
state = ckpt.get("model_state_dict", ckpt)
missing, unexpected = model.load_state_dict(state, strict=False)
if missing or unexpected:
    print(f"[WARN] Missing keys: {len(missing)}; Unexpected: {len(unexpected)}")
model.eval()
print("[OK] Model loaded from:", weights_dict)


# =========================
#   PATCH PIPELINE UTILS
# =========================
def patch_transform(patch_f01_3ch: np.ndarray) -> torch.Tensor:
    """H×W×3 float[0,1] -> torch.FloatTensor [3,H,W], normalized with scalar mean/std."""
    x3 = np.transpose(patch_f01_3ch, (2, 0, 1))  # C×H×W
    x3 = (x3 - mean_pixel) / (std_pixel if std_pixel > 0 else 1.0)
    return torch.from_numpy(x3).float()

@torch.no_grad()
def infer_patch_probs(patches_np, batch_size=64):
    all_probs = []
    for k in range(0, len(patches_np), batch_size):
        batch_np = patches_np[k:k+batch_size]
        batch_t  = torch.stack([patch_transform(p) for p in batch_np], dim=0).to(device)
        logits   = model(batch_t)
        probs    = F.softmax(logits, dim=1).cpu().numpy()
        all_probs.append(probs)
    return np.concatenate(all_probs, axis=0)


def save_heatmap_overlay(im_f01_gray: np.ndarray, hm01: np.ndarray, out_path: str, out_px: int = 256):
    base_u8 = (np.clip(im_f01_gray, 0, 1) * 255).astype(np.uint8)
    hm_u8   = (np.clip(hm01,        0, 1) * 255).astype(np.uint8)

    base_u8 = cv2.resize(base_u8, (out_px, out_px), interpolation=cv2.INTER_AREA)
    hm_u8   = cv2.resize(hm_u8,   (out_px, out_px), interpolation=cv2.INTER_LINEAR)

    heat_rgb = cv2.applyColorMap(hm_u8, cv2.COLORMAP_JET)          # BGR by default
    gray_rgb = cv2.cvtColor(base_u8, cv2.COLOR_GRAY2BGR)

    overlay  = cv2.addWeighted(gray_rgb, 1.0, heat_rgb, 0.35, 0.0) # alpha=0.35
    cv2.imwrite(out_path, overlay)


# =========================
#  SINGLE-IMAGE PROCESSOR
# =========================
def process_one_image(img_path: str, fwhm: float, scale: float):
    """Returns (heatmap_float01_HxW, warped_float01_HxW, base_gray_float01) or raises on fatal error."""
    # ------- IMAGE I/O -------
    im = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)
    if im is None:
        raise FileNotFoundError(f"Could not read image: {img_path}")
    if im.ndim == 3 and im.shape[2] == 3:
        im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)

    # Normalize depending on bit depth
    if im.dtype == np.uint16:
        im_f01_gray = im.astype(np.float32) / 65535.0
    elif im.dtype == np.uint8:
        im_f01_gray = im.astype(np.float32) / 255.0
    else:
        im_f01_gray = np.clip(im.astype(np.float32), 0, 1)

    H, W = im_f01_gray.shape

    # Ensure image large enough for patches
    if H < patch_size or W < patch_size:
        raise ValueError(f"Image ({H}x{W}) smaller than patch_size={patch_size}")

    # 3-channel float image in [0,1] for patching
    image_np = np.stack([im_f01_gray, im_f01_gray, im_f01_gray], axis=-1)

    # ------- PATCHES + INFERENCE -------
    patches = extract_patches(image_np, patch_size, stride)
    N = len(patches)
    if N == 0:
        raise RuntimeError("No patches extracted — check patch_size/stride vs image size.")

    probs = infer_patch_probs(patches, batch_size=batch_size)
    if probs.shape != (N, num_classes):
        raise RuntimeError(f"Unexpected probs shape {probs.shape}, expected {(N, num_classes)}")

    # ------- HEATMAP BUILD -------
    grid_h = (H - patch_size) // stride + 1
    grid_w = (W - patch_size) // stride + 1
    if grid_h * grid_w != N:
        raise RuntimeError(f"Grid mismatch: expected {grid_h*grid_w} patches, got {N}")

    pos_idx = 1 if num_classes > 1 else 0
    heat_grid = probs[:, pos_idx].reshape(grid_h, grid_w)

    # Linear interpolation; clip to [0,1]
    hm = cv2.resize(heat_grid, (W, H), interpolation=cv2.INTER_LINEAR)
    hm = np.clip(hm, 0.0, 1.0)

    # ------- WARP -------
    img_t  = torch.from_numpy(im_f01_gray.astype(np.float32))  # HxW
    heat_t = torch.from_numpy(hm.astype(np.float32))           # HxW

    #p_img, pixel_grid = warped_imgs(img_t, heat_t, (H, W), fwhm, scale)
    p_img, pixel_grid = warped_imgs(img_t, heat_t, (256, 256), fwhm, scale)
    warped = p_img[0, 0].detach().cpu().numpy()  # float in [0,1]
    warped = np.clip(warped, 0.0, 1.0)

    return hm, warped, im_f01_gray


# =========================
#     DATASET LOOP
# =========================
def main():
    # Read CSV
    if not os.path.exists(bbox_csv):
        raise FileNotFoundError(f"CSV not found: {bbox_csv}")
    df = pd.read_csv(bbox_csv)
    if 'path' not in df.columns:
        raise KeyError("CSV must contain a 'path' column with image paths.")

    # Use every unique path (no bbox filtering)
    img_paths_all = (
        df['path']
        .astype(str)
        .dropna()
        .drop_duplicates()
        .tolist()
    )

    # Optionally filter out non-existent files to avoid crashes
    img_paths = [p for p in img_paths_all if os.path.exists(p)]
    missing = len(img_paths_all) - len(img_paths)
    print(f"[INFO] Found {len(img_paths_all)} unique image paths in CSV "
          f"(processing {len(img_paths)} existing files; missing: {missing}).")


    # ===========
    # SWEEP LOOP
    # ===========
    for fwhm in fwhm_values:
        for scale in scale_values:
            _scale_s = _fmt_simple(scale)
            _fwhm_s  = _fmt_simple(fwhm)

            # Base folder per (scale, fwhm)
            base_out = os.path.join(_base_root, f"scale{_scale_s}_fwhm{_fwhm_s}")
            os.makedirs(base_out, exist_ok=True)

            # Subfolders
            out_warp_dir = os.path.join(base_out, f"warped_images_scale{_scale_s}_fwhm{_fwhm_s}")
            out_heat_dir = os.path.join(base_out, f"heatmaps_scale{_scale_s}_fwhm{_fwhm_s}")
            os.makedirs(out_warp_dir, exist_ok=True)
            os.makedirs(out_heat_dir, exist_ok=True)

            print(f"\n[PARAMS] scale={scale}, fwhm={fwhm}")
            print(f"[OUT] base   -> {base_out}")
            print(f"[OUT] warped -> {out_warp_dir}")
            print(f"[OUT] heat   -> {out_heat_dir}")

            # Process images with a progress bar (per-parameter combo)
            for idx, img_path in enumerate(tqdm(img_paths, desc=f"Warping images (s={_scale_s}, f={_fwhm_s})", unit="img")):
                try:
                    hm, warped, base_gray = process_one_image(img_path, fwhm=fwhm, scale=scale)
                except Exception as e:
                    print(f"[ERR] Skipping index {idx} ({img_path}): {e}")
                    continue

                # --- SAVE HEATMAP OVERLAY (PNG) ---
                heat_overlay_out = os.path.join(out_heat_dir, f"heatmap_image_{idx}.png")
                try:
                    save_heatmap_overlay(base_gray, hm, heat_overlay_out)
                except Exception as e:
                    print(f"[WARN] Failed to save heatmap overlay: {heat_overlay_out} ({e})")

                # --- SAVE WARPED IMAGE (PNG, 8-bit grayscale) ---
                warped_u8 = (np.clip(warped, 0.0, 1.0) * 255.0).astype(np.uint8)
                warp_out = os.path.join(out_warp_dir, f"warped_image_{idx}.png")
                ok_w = cv2.imwrite(warp_out, warped_u8)
                if not ok_w:
                    print(f"[WARN] Failed to save warped image: {warp_out}")

    print("\n[DONE] All images processed for all parameter combinations.")

if __name__ == "__main__":
    main()
